{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict __Price of a bottle of wine__\n",
    "\n",
    "# Summary\n",
    "\n",
    "The data summarize **258210** wine reviews:\n",
    "\n",
    "__175000__ are the training set, the data on which to train your models;\n",
    "\n",
    "The remaining __83210__ observations constitute the validation set (or score set), or the data on which you must make the estimate for the submission. The validation set at your disposal obviously does not contain the variable price, the price of the bottle of wine that the goal of your forecast.\n",
    "\n",
    " \n",
    "\n",
    "## File descriptions\n",
    "\n",
    "    - train.csv - the training set\n",
    "    - test.csv - the test set\n",
    "    - Sample_Submission.csv  - a sample submission file in the correct format\n",
    " \n",
    "### Data fields\n",
    "\n",
    "**country (String)** The country that the wine is from\n",
    "\n",
    "**province (String)** The province or state that the wine is from\n",
    "\n",
    "**region_1 (String)** The wine growing area in a province or state (ie Napa)\n",
    "\n",
    "**region_2 (String)** Sometimes there are more specific regions within the wine growing area (ie Rutherford inside the Napa Valley), but this value can sometimes be blank\n",
    "\n",
    "**winery (String)** The winery that made the wine\n",
    "\n",
    "**variety (String)** The type of grapes used to make the wine (ie Pinot Noir)\n",
    "\n",
    "**designation (String)** The vineyard within the winery where the grapes that made the wine are from\n",
    "\n",
    "**taster_name (String)** taster name\n",
    "\n",
    "**taster_twitter_handle (String)** taster twitter account name\n",
    "\n",
    "**description (String)** A few sentences from a sommelier describing the wine's taste, smell, look, feel, etc.\n",
    "\n",
    "**points (Numeric)** Number of points WineEnthusiast rated the wine on a scale of **1-100**\n",
    "\n",
    "## __TARGET: price (Numeric) The cost for a bottle of wine__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of your forecasts will be evaluated using the Root Mean Squared Error (RMSE).\n",
    "\n",
    "An example code for the calculation:\n",
    "\n",
    "RMSE = sqrt (mean ((predicted-true) ^ 2))\n",
    "\n",
    "This leaderboard is calculated with approximately 30% of the test data.\n",
    "\n",
    "The final results will be based on the other 70%, so the final standings may be different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "[nltk_data] Error loading punkt: <urlopen error [Errno -2] Name or\n",
      "[nltk_data]     service not known>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [Errno -2] Name or\n",
      "[nltk_data]     service not known>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.17.3\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import tensorflow as tf\n",
    "# tf.enable_eager_execution()\n",
    "\n",
    "from keras.datasets import imdb\n",
    "from keras import preprocessing\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout\n",
    "\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Downgrate numpy to fix a problem\n",
    "# !pip install numpy==1.16.2\n",
    "import numpy as np\n",
    "print(np.__version__)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import string\n",
    "\n",
    "# !pip install ipdb\n",
    "import ipdb # deb\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "# Spliting data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import metrics # For RUC\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "# from google.colab import files\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "import logging\n",
    "logging.getLogger('googleapiclient.discovery_cache').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./Datasets/train.csv\")\n",
    "test = pd.read_csv(\"./Datasets/test.csv\")\n",
    "test.drop(['price', 'index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['country'] = df['country'].fillna('') + ' ' + df['province'].fillna('')+\\\n",
    "    ' ' + df['region_1'].fillna('')+' ' + df['region_2'].fillna('')\n",
    "    df['text'] = (df['description'].fillna('') + ' ' + df['country'] + ' ' + df['designation'].fillna(''))\n",
    "    df['info'] = (df['text'].fillna('')+' '+df['taster_name'].fillna('')+' '+\\\n",
    "                  df['taster_twitter_handle'].fillna('')+\\\n",
    "                 ' ' + df['title'].fillna('') + df['variety'].fillna('')+df['winery'].fillna(''))\n",
    "    return df[['country', 'text', 'info']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Method (In class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "from subprocess import check_output\n",
    "# print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./Datasets/train.csv\")\n",
    "test = pd.read_csv(\"./Datasets/test.csv\")\n",
    "test.drop(['price', 'index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna(value='missing', inplace=True)\n",
    "test.fillna(value='missing', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['target'] = np.log1p(train['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>taster_twitter_handle</th>\n",
       "      <th>title</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>This is a fine rich balanced wine. It has ripe...</td>\n",
       "      <td>Vila Santa Reserva</td>\n",
       "      <td>88.870874</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Alentejano</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>PORTUGUESE RED</td>\n",
       "      <td>J. Portugal Ramos</td>\n",
       "      <td>32027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>France</td>\n",
       "      <td>A solid, chunky wine, with a structure that is...</td>\n",
       "      <td>missing</td>\n",
       "      <td>88.041695</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Bordeaux</td>\n",
       "      <td>Lalande de Pomerol</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>BORDEAUX-STYLE RED BLEND</td>\n",
       "      <td>Château Tour Grand Colombier</td>\n",
       "      <td>71079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>France</td>\n",
       "      <td>This is powerful and concentrated, with the hi...</td>\n",
       "      <td>missing</td>\n",
       "      <td>94.085021</td>\n",
       "      <td>130.0</td>\n",
       "      <td>Bordeaux</td>\n",
       "      <td>Saint-Émilion</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>BORDEAUX-STYLE RED BLEND</td>\n",
       "      <td>Château Figeac</td>\n",
       "      <td>32440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>Rich, ripe and oaky, this Petite Sirah charms ...</td>\n",
       "      <td>Thompson Vineyard</td>\n",
       "      <td>89.869797</td>\n",
       "      <td>34.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Santa Barbara County</td>\n",
       "      <td>Central Coast</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>Jaffurs 2010 Thompson Vineyard Petite Sirah (S...</td>\n",
       "      <td>PETITE SIRAH</td>\n",
       "      <td>Jaffurs</td>\n",
       "      <td>124405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>This wine is a unique in the state blend and f...</td>\n",
       "      <td>McKinley Springs Vineyard</td>\n",
       "      <td>89.017651</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Horse Heaven Hills</td>\n",
       "      <td>Columbia Valley</td>\n",
       "      <td>Sean P. Sullivan</td>\n",
       "      <td>@wawinereport</td>\n",
       "      <td>Syncline 2016 McKinley Springs Vineyard Rosé (...</td>\n",
       "      <td>ROSé</td>\n",
       "      <td>Syncline</td>\n",
       "      <td>33649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country                                        description  \\\n",
       "0  Portugal  This is a fine rich balanced wine. It has ripe...   \n",
       "1    France  A solid, chunky wine, with a structure that is...   \n",
       "2    France  This is powerful and concentrated, with the hi...   \n",
       "3        US  Rich, ripe and oaky, this Petite Sirah charms ...   \n",
       "4        US  This wine is a unique in the state blend and f...   \n",
       "\n",
       "                 designation     points  price    province  \\\n",
       "0         Vila Santa Reserva  88.870874   20.0  Alentejano   \n",
       "1                    missing  88.041695   28.0    Bordeaux   \n",
       "2                    missing  94.085021  130.0    Bordeaux   \n",
       "3          Thompson Vineyard  89.869797   34.0  California   \n",
       "4  McKinley Springs Vineyard  89.017651   24.0  Washington   \n",
       "\n",
       "               region_1         region_2       taster_name  \\\n",
       "0               missing          missing           missing   \n",
       "1    Lalande de Pomerol          missing           missing   \n",
       "2         Saint-Émilion          missing           missing   \n",
       "3  Santa Barbara County    Central Coast           missing   \n",
       "4    Horse Heaven Hills  Columbia Valley  Sean P. Sullivan   \n",
       "\n",
       "  taster_twitter_handle                                              title  \\\n",
       "0               missing                                            missing   \n",
       "1               missing                                            missing   \n",
       "2               missing                                            missing   \n",
       "3               missing  Jaffurs 2010 Thompson Vineyard Petite Sirah (S...   \n",
       "4         @wawinereport  Syncline 2016 McKinley Springs Vineyard Rosé (...   \n",
       "\n",
       "                    variety                        winery      id  \n",
       "0            PORTUGUESE RED             J. Portugal Ramos   32027  \n",
       "1  BORDEAUX-STYLE RED BLEND  Château Tour Grand Colombier   71079  \n",
       "2  BORDEAUX-STYLE RED BLEND                Château Figeac   32440  \n",
       "3              PETITE SIRAH                       Jaffurs  124405  \n",
       "4                      ROSé                      Syncline   33649  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>taster_twitter_handle</th>\n",
       "      <th>title</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83205</th>\n",
       "      <td>US</td>\n",
       "      <td>A simple, direct wine, pretty full-bodied for ...</td>\n",
       "      <td>Le Pique-Nique</td>\n",
       "      <td>81.961663</td>\n",
       "      <td>California</td>\n",
       "      <td>Sonoma Valley</td>\n",
       "      <td>Sonoma</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>ROSé</td>\n",
       "      <td>Wellington</td>\n",
       "      <td>83205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83206</th>\n",
       "      <td>US</td>\n",
       "      <td>This dry, spicy wine shows the rustic, rugged ...</td>\n",
       "      <td>Rebecca's Vineyard</td>\n",
       "      <td>87.162191</td>\n",
       "      <td>California</td>\n",
       "      <td>Dry Creek Valley</td>\n",
       "      <td>Sonoma</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>CABERNET SAUVIGNON</td>\n",
       "      <td>Forth</td>\n",
       "      <td>83206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83207</th>\n",
       "      <td>Italy</td>\n",
       "      <td>Attractive apricot, peach and honey aromas vie...</td>\n",
       "      <td>Aurente</td>\n",
       "      <td>89.057585</td>\n",
       "      <td>Central Italy</td>\n",
       "      <td>Umbria</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>CHARDONNAY</td>\n",
       "      <td>Lungarotti</td>\n",
       "      <td>83207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83208</th>\n",
       "      <td>France</td>\n",
       "      <td>Red cherries and jelly fruits highlight a wine...</td>\n",
       "      <td>missing</td>\n",
       "      <td>84.907909</td>\n",
       "      <td>Burgundy</td>\n",
       "      <td>Bourgogne</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>PINOT NOIR</td>\n",
       "      <td>Bouchard Père &amp; Fils</td>\n",
       "      <td>83208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83209</th>\n",
       "      <td>Italy</td>\n",
       "      <td>Tasca d'Almerita makes what may be the best ex...</td>\n",
       "      <td>missing</td>\n",
       "      <td>92.038702</td>\n",
       "      <td>Sicily &amp; Sardinia</td>\n",
       "      <td>Sicilia</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>CABERNET SAUVIGNON</td>\n",
       "      <td>Tasca d'Almerita</td>\n",
       "      <td>83209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      country                                        description  \\\n",
       "83205      US  A simple, direct wine, pretty full-bodied for ...   \n",
       "83206      US  This dry, spicy wine shows the rustic, rugged ...   \n",
       "83207   Italy  Attractive apricot, peach and honey aromas vie...   \n",
       "83208  France  Red cherries and jelly fruits highlight a wine...   \n",
       "83209   Italy  Tasca d'Almerita makes what may be the best ex...   \n",
       "\n",
       "              designation     points           province          region_1  \\\n",
       "83205      Le Pique-Nique  81.961663         California     Sonoma Valley   \n",
       "83206  Rebecca's Vineyard  87.162191         California  Dry Creek Valley   \n",
       "83207             Aurente  89.057585      Central Italy            Umbria   \n",
       "83208             missing  84.907909           Burgundy         Bourgogne   \n",
       "83209             missing  92.038702  Sicily & Sardinia           Sicilia   \n",
       "\n",
       "      region_2 taster_name taster_twitter_handle    title             variety  \\\n",
       "83205   Sonoma     missing               missing  missing                ROSé   \n",
       "83206   Sonoma     missing               missing  missing  CABERNET SAUVIGNON   \n",
       "83207  missing     missing               missing  missing          CHARDONNAY   \n",
       "83208  missing     missing               missing  missing          PINOT NOIR   \n",
       "83209  missing     missing               missing  missing  CABERNET SAUVIGNON   \n",
       "\n",
       "                     winery     id  \n",
       "83205            Wellington  83205  \n",
       "83206                 Forth  83206  \n",
       "83207            Lungarotti  83207  \n",
       "83208  Bouchard Père & Fils  83208  \n",
       "83209      Tasca d'Almerita  83209  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling categorical variables...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>taster_twitter_handle</th>\n",
       "      <th>title</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>This is a fine rich balanced wine. It has ripe...</td>\n",
       "      <td>Vila Santa Reserva</td>\n",
       "      <td>88.870874</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8</td>\n",
       "      <td>missing</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>missing</td>\n",
       "      <td>PORTUGUESE RED</td>\n",
       "      <td>J. Portugal Ramos</td>\n",
       "      <td>32027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>A solid, chunky wine, with a structure that is...</td>\n",
       "      <td>missing</td>\n",
       "      <td>88.041695</td>\n",
       "      <td>28.0</td>\n",
       "      <td>38</td>\n",
       "      <td>Lalande de Pomerol</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>missing</td>\n",
       "      <td>BORDEAUX-STYLE RED BLEND</td>\n",
       "      <td>Château Tour Grand Colombier</td>\n",
       "      <td>71079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>This is powerful and concentrated, with the hi...</td>\n",
       "      <td>missing</td>\n",
       "      <td>94.085021</td>\n",
       "      <td>130.0</td>\n",
       "      <td>38</td>\n",
       "      <td>Saint-Émilion</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>missing</td>\n",
       "      <td>BORDEAUX-STYLE RED BLEND</td>\n",
       "      <td>Château Figeac</td>\n",
       "      <td>32440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country                                        description  \\\n",
       "0       34  This is a fine rich balanced wine. It has ripe...   \n",
       "1       15  A solid, chunky wine, with a structure that is...   \n",
       "2       15  This is powerful and concentrated, with the hi...   \n",
       "\n",
       "          designation     points  price  province            region_1  \\\n",
       "0  Vila Santa Reserva  88.870874   20.0         8             missing   \n",
       "1             missing  88.041695   28.0        38  Lalande de Pomerol   \n",
       "2             missing  94.085021  130.0        38       Saint-Émilion   \n",
       "\n",
       "   region_2  taster_name  taster_twitter_handle    title  \\\n",
       "0        18           19                     15  missing   \n",
       "1        18           19                     15  missing   \n",
       "2        18           19                     15  missing   \n",
       "\n",
       "                    variety                        winery     id  \n",
       "0            PORTUGUESE RED             J. Portugal Ramos  32027  \n",
       "1  BORDEAUX-STYLE RED BLEND  Château Tour Grand Colombier  71079  \n",
       "2  BORDEAUX-STYLE RED BLEND                Château Figeac  32440  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Handling categorical variables...\")\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(np.hstack([train.country, test.country]))\n",
    "train['country'] = le.transform(train.country)\n",
    "test['country'] = le.transform(test.country)\n",
    "\n",
    "le.fit(np.hstack([train.province, test.province]))\n",
    "train['province'] = le.transform(train.province)\n",
    "test['province'] = le.transform(test.province)\n",
    "\n",
    "le.fit(np.hstack([train.taster_name, test.taster_name]))\n",
    "train['taster_name'] = le.transform(train.taster_name)\n",
    "test['taster_name'] = le.transform(test.taster_name)\n",
    "\n",
    "le.fit(np.hstack([train.taster_twitter_handle, test.taster_twitter_handle]))\n",
    "train['taster_twitter_handle'] = le.transform(train.taster_twitter_handle)\n",
    "test['taster_twitter_handle'] = le.transform(test.taster_twitter_handle)\n",
    "\n",
    "le.fit(np.hstack([train.region_2, test.region_2]))\n",
    "train['region_2'] = le.transform(train.region_2)\n",
    "test['region_2'] = le.transform(test.region_2)\n",
    "\n",
    "# le.fit(np.hstack([train.id, test.id]))\n",
    "# train['id'] = le.transform(train.id)\n",
    "# test['id'] = le.transform(test.id)\n",
    "\n",
    "del le\n",
    "\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to seq process...\n",
      "   Fitting tokenizer...\n",
      "   Transforming text to seq...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>taster_twitter_handle</th>\n",
       "      <th>title</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "      <th>id</th>\n",
       "      <th>seq_description</th>\n",
       "      <th>seq_designation</th>\n",
       "      <th>seq_region_1</th>\n",
       "      <th>seq_title</th>\n",
       "      <th>seq_variety</th>\n",
       "      <th>seq_winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>This is a fine rich balanced wine. It has ripe...</td>\n",
       "      <td>Vila Santa Reserva</td>\n",
       "      <td>88.870874</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8</td>\n",
       "      <td>missing</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>missing</td>\n",
       "      <td>PORTUGUESE RED</td>\n",
       "      <td>J. Portugal Ramos</td>\n",
       "      <td>32027</td>\n",
       "      <td>[7, 8, 3, 127, 51, 107, 9, 13, 40, 37, 78, 19,...</td>\n",
       "      <td>[3613, 102, 160]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[311, 15]</td>\n",
       "      <td>[659, 1789, 2300]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>A solid, chunky wine, with a structure that is...</td>\n",
       "      <td>missing</td>\n",
       "      <td>88.041695</td>\n",
       "      <td>28.0</td>\n",
       "      <td>38</td>\n",
       "      <td>Lalande de Pomerol</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>missing</td>\n",
       "      <td>BORDEAUX-STYLE RED BLEND</td>\n",
       "      <td>Château Tour Grand Colombier</td>\n",
       "      <td>71079</td>\n",
       "      <td>[3, 242, 614, 9, 6, 3, 131, 19, 8, 60, 4, 7094...</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[3591, 43, 2529]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[86, 58, 15, 20]</td>\n",
       "      <td>[101, 1804, 375, 10929]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>This is powerful and concentrated, with the hi...</td>\n",
       "      <td>missing</td>\n",
       "      <td>94.085021</td>\n",
       "      <td>130.0</td>\n",
       "      <td>38</td>\n",
       "      <td>Saint-Émilion</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>missing</td>\n",
       "      <td>BORDEAUX-STYLE RED BLEND</td>\n",
       "      <td>Château Figeac</td>\n",
       "      <td>32440</td>\n",
       "      <td>[7, 8, 332, 1, 184, 6, 2, 213, 2228, 4, 27, 23...</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[430, 1258]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[86, 58, 15, 20]</td>\n",
       "      <td>[101, 9386]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country                                        description  \\\n",
       "0       34  This is a fine rich balanced wine. It has ripe...   \n",
       "1       15  A solid, chunky wine, with a structure that is...   \n",
       "2       15  This is powerful and concentrated, with the hi...   \n",
       "\n",
       "          designation     points  price  province            region_1  \\\n",
       "0  Vila Santa Reserva  88.870874   20.0         8             missing   \n",
       "1             missing  88.041695   28.0        38  Lalande de Pomerol   \n",
       "2             missing  94.085021  130.0        38       Saint-Émilion   \n",
       "\n",
       "   region_2  taster_name  taster_twitter_handle    title  \\\n",
       "0        18           19                     15  missing   \n",
       "1        18           19                     15  missing   \n",
       "2        18           19                     15  missing   \n",
       "\n",
       "                    variety                        winery     id  \\\n",
       "0            PORTUGUESE RED             J. Portugal Ramos  32027   \n",
       "1  BORDEAUX-STYLE RED BLEND  Château Tour Grand Colombier  71079   \n",
       "2  BORDEAUX-STYLE RED BLEND                Château Figeac  32440   \n",
       "\n",
       "                                     seq_description   seq_designation  \\\n",
       "0  [7, 8, 3, 127, 51, 107, 9, 13, 40, 37, 78, 19,...  [3613, 102, 160]   \n",
       "1  [3, 242, 614, 9, 6, 3, 131, 19, 8, 60, 4, 7094...               [5]   \n",
       "2  [7, 8, 332, 1, 184, 6, 2, 213, 2228, 4, 27, 23...               [5]   \n",
       "\n",
       "       seq_region_1 seq_title       seq_variety               seq_winery  \n",
       "0               [5]       [5]         [311, 15]        [659, 1789, 2300]  \n",
       "1  [3591, 43, 2529]       [5]  [86, 58, 15, 20]  [101, 1804, 375, 10929]  \n",
       "2       [430, 1258]       [5]  [86, 58, 15, 20]              [101, 9386]  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PROCESS TEXT: RAW\n",
    "print(\"Text to seq process...\")\n",
    "print(\"   Fitting tokenizer...\")\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "raw_text = np.hstack([train.description.str.lower(), \n",
    "                      train.designation.str.lower(), \n",
    "                      train.region_1.str.lower(),\n",
    "                      train.title.str.lower(),\n",
    "                      train.variety.str.lower(),\n",
    "                      train.winery.str.lower()])\n",
    "\n",
    "tok_raw = Tokenizer()\n",
    "tok_raw.fit_on_texts(raw_text)\n",
    "print(\"   Transforming text to seq...\")\n",
    "\n",
    "train[\"seq_description\"] = tok_raw.texts_to_sequences(train.description.str.lower())\n",
    "test[\"seq_description\"] = tok_raw.texts_to_sequences(test.description.str.lower())\n",
    "\n",
    "train[\"seq_designation\"] = tok_raw.texts_to_sequences(train.designation.str.lower())\n",
    "test[\"seq_designation\"] = tok_raw.texts_to_sequences(test.designation.str.lower())\n",
    "\n",
    "train[\"seq_region_1\"] = tok_raw.texts_to_sequences(train.region_1.str.lower())\n",
    "test[\"seq_region_1\"] = tok_raw.texts_to_sequences(test.region_1.str.lower())\n",
    "\n",
    "train[\"seq_title\"] = tok_raw.texts_to_sequences(train.title.str.lower())\n",
    "test[\"seq_title\"] = tok_raw.texts_to_sequences(test.title.str.lower())\n",
    "\n",
    "train[\"seq_variety\"] = tok_raw.texts_to_sequences(train.variety.str.lower())\n",
    "test[\"seq_variety\"] = tok_raw.texts_to_sequences(test.variety.str.lower())\n",
    "\n",
    "train[\"seq_winery\"] = tok_raw.texts_to_sequences(train.winery.str.lower())\n",
    "test[\"seq_winery\"] = tok_raw.texts_to_sequences(test.winery.str.lower())\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 175000 entries, 0 to 174999\n",
      "Data columns (total 20 columns):\n",
      "country                  175000 non-null int64\n",
      "description              175000 non-null object\n",
      "designation              175000 non-null object\n",
      "points                   175000 non-null float64\n",
      "price                    175000 non-null float64\n",
      "province                 175000 non-null int64\n",
      "region_1                 175000 non-null object\n",
      "region_2                 175000 non-null int64\n",
      "taster_name              175000 non-null int64\n",
      "taster_twitter_handle    175000 non-null int64\n",
      "title                    175000 non-null object\n",
      "variety                  175000 non-null object\n",
      "winery                   175000 non-null object\n",
      "id                       175000 non-null int64\n",
      "seq_description          175000 non-null object\n",
      "seq_designation          175000 non-null object\n",
      "seq_region_1             175000 non-null object\n",
      "seq_title                175000 non-null object\n",
      "seq_variety              175000 non-null object\n",
      "seq_winery               175000 non-null object\n",
      "dtypes: float64(2), int64(6), object(12)\n",
      "memory usage: 26.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.953577142857142"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['winery'].apply(lambda x: len(x) ).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EMBEDDINGS MAX VALUE\n",
    "#Base on the histograms, we select the next lengths\n",
    "MAX_Description = 245\n",
    "MAX_Designation = 13\n",
    "MAX_Region_1 = 13\n",
    "MAX_Title = 29\n",
    "MAX_Variety = 12\n",
    "MAX_Winery = 12\n",
    "\n",
    "MAX_TEXT = np.max([np.max(train.seq_description.max())\n",
    "                   , np.max(test.seq_description.max())\n",
    "                   , np.max(train.seq_designation.max())\n",
    "                   , np.max(test.seq_designation.max())\n",
    "                   , np.max(train.seq_region_1.max())\n",
    "                   , np.max(test.seq_region_1.max())\n",
    "                   , np.max(train.seq_title.max())\n",
    "                   , np.max(test.seq_title.max())\n",
    "                   , np.max(train.seq_variety.max())\n",
    "                   , np.max(test.seq_variety.max())\n",
    "                   , np.max(train.seq_winery.max())\n",
    "                   , np.max(test.seq_winery.max())])+2\n",
    "MAX_Country = np.max([train.country.max(), test.country.max()])+1\n",
    "MAX_Province = np.max([train.province.max(), test.province.max()])+1\n",
    "MAX_Taster_name = np.max([train.taster_name.max(), test.taster_name.max()])+1\n",
    "MAX_Taster_twitter_handle = np.max([train.taster_twitter_handle.max(), test.taster_twitter_handle.max()])+1\n",
    "MAX_Region_2 = np.max([train.region_2.max(), test.region_2.max()])+1\n",
    "# MAX_id= np.max([train.id.max(), test.id.max()])+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fa0e5871320>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# target_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "# train[\"target\"] = target_scaler.fit_transform(train[['target']].values.reshape(-1,1))\n",
    "train[\"target\"] = train[\"price\"]\n",
    "pd.DataFrame(train.target).hist()\n",
    "\n",
    "# train[\"target\"] = np.log(train.price+1)\n",
    "# target_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "# train[\"target\"] = target_scaler.fit_transform(train[['target']].values.reshape(-1,1))\n",
    "# pd.DataFrame(train.target).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174982, 21)\n",
      "(18, 21)\n"
     ]
    }
   ],
   "source": [
    "#EXTRACT DEVELOPTMENT TEST\n",
    "dtrain, dvalid = train_test_split(train, random_state=123, train_size=0.9999)\n",
    "print(dtrain.shape)\n",
    "print(dvalid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KERAS DATA DEFINITION\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def get_keras_data(dataset):\n",
    "    X = {\n",
    "        'country': np.array(dataset.country)\n",
    "        ,'description': pad_sequences(dataset.seq_description, \n",
    "                                      maxlen=MAX_Description)\n",
    "        ,'designation': pad_sequences(dataset.seq_designation, \n",
    "                                      maxlen=MAX_Description)\n",
    "        ,'points_imp': np.array(dataset[[\"points\"]])\n",
    "        ,'province': np.array(dataset.province)\n",
    "        ,'region_1': pad_sequences(dataset.seq_region_1, \n",
    "                                   maxlen=MAX_Region_1)\n",
    "        ,'region_2': np.array(dataset.region_2)\n",
    "        ,'taster_name': np.array(dataset.taster_name)\n",
    "        ,'taster_twitter_handle': np.array(dataset.taster_twitter_handle)\n",
    "        ,'title': pad_sequences(dataset.seq_title\n",
    "                                        , maxlen=MAX_Title)\n",
    "        ,'variety': pad_sequences(dataset.seq_variety\n",
    "                                        , maxlen=MAX_Variety)\n",
    "        ,'winery': pad_sequences(dataset.seq_winery\n",
    "                                        , maxlen=MAX_Winery)\n",
    "    }\n",
    "    return X\n",
    "\n",
    "X_train = get_keras_data(dtrain)\n",
    "X_valid = get_keras_data(dvalid)\n",
    "X_test = get_keras_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "country (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "province (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "region_2 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "taster_name (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "taster_twitter_handle (InputLay (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "description (InputLayer)        (None, 245)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "designation (InputLayer)        (None, 245)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "region_1 (InputLayer)           (None, 13)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title (InputLayer)              (None, 29)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "variety (InputLayer)            (None, 12)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "winery (InputLayer)             (None, 12)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_100 (Embedding)       (None, 1, 20)        980         country[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_103 (Embedding)       (None, 1, 60)        29040       province[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_105 (Embedding)       (None, 1, 20)        380         region_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_106 (Embedding)       (None, 1, 10)        200         taster_name[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_107 (Embedding)       (None, 1, 20)        320         taster_twitter_handle[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_101 (Embedding)       (None, 245, 200)     12496800    description[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_102 (Embedding)       (None, 245, 60)      3749040     designation[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_104 (Embedding)       (None, 13, 60)       3749040     region_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_108 (Embedding)       (None, 29, 10)       624840      title[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_109 (Embedding)       (None, 12, 10)       624840      variety[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_110 (Embedding)       (None, 12, 10)       624840      winery[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_46 (Flatten)            (None, 20)           0           embedding_100[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_47 (Flatten)            (None, 60)           0           embedding_103[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_48 (Flatten)            (None, 20)           0           embedding_105[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_49 (Flatten)            (None, 10)           0           embedding_106[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_50 (Flatten)            (None, 20)           0           embedding_107[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gru_7 (GRU)                     (None, 64)           50880       embedding_101[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_49 (LSTM)                  (None, 32)           11904       embedding_102[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gru_8 (GRU)                     (None, 16)           3696        embedding_104[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_50 (LSTM)                  (None, 16)           1728        embedding_108[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gru_9 (GRU)                     (None, 16)           1296        embedding_109[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_51 (LSTM)                  (None, 8)            608         embedding_110[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "points_imp (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 283)          0           flatten_46[0][0]                 \n",
      "                                                                 flatten_47[0][0]                 \n",
      "                                                                 flatten_48[0][0]                 \n",
      "                                                                 flatten_49[0][0]                 \n",
      "                                                                 flatten_50[0][0]                 \n",
      "                                                                 gru_7[0][0]                      \n",
      "                                                                 lstm_49[0][0]                    \n",
      "                                                                 gru_8[0][0]                      \n",
      "                                                                 lstm_50[0][0]                    \n",
      "                                                                 gru_9[0][0]                      \n",
      "                                                                 lstm_51[0][0]                    \n",
      "                                                                 points_imp[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 512)          145408      concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 512)          0           dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 16)           8208        dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 16)           0           dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 1)            17          dropout_20[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 22,124,065\n",
      "Trainable params: 22,124,065\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#KERAS MODEL DEFINITION\n",
    "from keras.layers import Input, Dropout, Dense, BatchNormalization, Activation, concatenate, GRU, Embedding, Flatten, BatchNormalization, LSTM\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras import backend as K\n",
    "\n",
    "def get_callbacks(filepath, patience=2):\n",
    "    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n",
    "#     msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    return es\n",
    "\n",
    "def rmse_cust(y_true, y_pred):\n",
    "    return np.sqrt(metrics.mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def get_model():\n",
    "    #params\n",
    "    dr_r = 0.05\n",
    "    dr_d = 0.05\n",
    "    \n",
    "    #Inputs\n",
    "    country = Input(shape=[1], name=\"country\")\n",
    "    description = Input(shape=[X_train[\"description\"].shape[1]], \n",
    "                        name=\"description\")\n",
    "    designation = Input(shape=[X_train[\"designation\"].shape[1]], \n",
    "                        name=\"designation\")\n",
    "    points_imp = Input(shape=[1], name=\"points_imp\")\n",
    "    province = Input(shape=[1], name=\"province\")\n",
    "    region_1 = Input(shape=[X_train[\"region_1\"].shape[1]], \n",
    "                     name=\"region_1\")\n",
    "    region_2 = Input(shape=[1], name=\"region_2\")\n",
    "    taster_name = Input(shape=[1], name=\"taster_name\")\n",
    "    taster_twitter_handle = Input(shape=[1], name=\"taster_twitter_handle\")\n",
    "    title = Input(shape=[X_train[\"title\"].shape[1]], \n",
    "                  name=\"title\")\n",
    "    variety = Input(shape=[X_train[\"variety\"].shape[1]], \n",
    "                  name=\"variety\")\n",
    "    winery = Input(shape=[X_train[\"winery\"].shape[1]], name=\"winery\")\n",
    "    \n",
    "    \n",
    "    #Embeddings layers\n",
    "    emb_size = 80\n",
    "        \n",
    "    emb_country = Embedding(MAX_Country, 20)(country)\n",
    "    emb_description = Embedding(MAX_TEXT, 200)(description)\n",
    "    emb_designation = Embedding(MAX_TEXT, 60)(designation)\n",
    "#     emb_category_name = Embedding(MAX_TEXT, emb_size//3)(category_name)\n",
    "    emb_province = Embedding(MAX_Province, 60)(province)\n",
    "    emb_region_1 = Embedding(MAX_TEXT, 60)(region_1)\n",
    "    emb_region_2 = Embedding(MAX_Region_2, 20)(region_2)\n",
    "    \n",
    "    emb_taster_name = Embedding(MAX_Taster_name, 10)(taster_name)\n",
    "    emb_taster_twitter_handle = Embedding(MAX_Taster_twitter_handle,\n",
    "                                          20)(taster_twitter_handle)\n",
    "    emb_title = Embedding(MAX_TEXT, 10)(title)\n",
    "    emb_variety = Embedding(MAX_TEXT, 10)(variety)\n",
    "    emb_winery = Embedding(MAX_TEXT, 10)(winery)\n",
    "    \n",
    "    #rnn layer\n",
    "    rnn_layer1 = GRU(64) (emb_description)\n",
    "    rnn_layer2 = LSTM(32) (emb_designation)\n",
    "    rnn_layer3 = GRU(16) (emb_region_1)\n",
    "    rnn_layer4 = LSTM(16) (emb_title)\n",
    "    rnn_layer5 = GRU(16) (emb_variety)\n",
    "    rnn_layer6 = LSTM(8) (emb_winery)\n",
    "    \n",
    "    #main layer\n",
    "    main_l = concatenate([\n",
    "        Flatten() (emb_country)\n",
    "        , Flatten() (emb_province)\n",
    "        , Flatten() (emb_region_2)\n",
    "        , Flatten() (emb_taster_name)\n",
    "        , Flatten() (emb_taster_twitter_handle)\n",
    "        , rnn_layer1\n",
    "        , rnn_layer2\n",
    "        , rnn_layer3\n",
    "        , rnn_layer4\n",
    "        , rnn_layer5\n",
    "        , rnn_layer6\n",
    "        , points_imp\n",
    "    ])\n",
    "    main_l = Dropout(dr_r) (Dense(512,activation='elu') (main_l))\n",
    "    main_l = Dropout(dr_d) (Dense(16,activation='elu') (main_l))\n",
    "    \n",
    "    #output\n",
    "    output = Dense(1, activation=\"linear\") (main_l)\n",
    "    \n",
    "    \n",
    "    #model\n",
    "    model = Model([country, description, designation,\n",
    "                   points_imp, province, region_1, region_2,\n",
    "                  taster_name, taster_twitter_handle, title,\n",
    "                  variety, winery], output)\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "    \n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            if(logs.get('val_mse')<250):\n",
    "                print(\"\\nReached 90% val_acc so cancelling training!\")\n",
    "                self.model.stop_training = True\n",
    "import numpy as np\n",
    "\n",
    "class EarlyStoppingAtMinLoss(tf.keras.callbacks.Callback):\n",
    "  \"\"\"Stop training when the loss is at its min, i.e. the loss stops decreasing.\n",
    "\n",
    "  Arguments:\n",
    "      patience: Number of epochs to wait after min has been hit. After this\n",
    "      number of no improvement, training stops.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, patience=2):\n",
    "    super(EarlyStoppingAtMinLoss, self).__init__()\n",
    "\n",
    "    self.patience = patience\n",
    "\n",
    "    # best_weights to store the weights at which the minimum loss occurs.\n",
    "    self.best_weights = None\n",
    "\n",
    "  def on_train_begin(self, logs=None):\n",
    "    # The number of epoch it has waited when loss is no longer minimum.\n",
    "    self.wait = 0\n",
    "    # The epoch the training stops at.\n",
    "    self.stopped_epoch = 0\n",
    "    # Initialize the best as infinity.\n",
    "    self.best = np.Inf\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    current = logs.get('loss')\n",
    "    if np.less(current, self.best):\n",
    "      self.best = current\n",
    "      self.wait = 0\n",
    "      # Record the best weights if current results is better (less).\n",
    "      self.best_weights = self.model.get_weights()\n",
    "    else:\n",
    "      self.wait += 1\n",
    "      if self.wait >= self.patience:\n",
    "        self.stopped_epoch = epoch\n",
    "        self.model.stop_training = True\n",
    "        print('Restoring model weights from the end of the best epoch.')\n",
    "        self.model.set_weights(self.best_weights)\n",
    "\n",
    "  def on_train_end(self, logs=None):\n",
    "    if self.stopped_epoch > 0:\n",
    "      print('Epoch %05d: early stopping' % (self.stopped_epoch + 1))\n",
    "    \n",
    "EarlyStoppingAtMinLoss = EarlyStoppingAtMinLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aims/anaconda3/envs/aims/lib/python3.5/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 174982 samples, validate on 18 samples\n",
      "Epoch 1/20\n",
      "174982/174982 [==============================] - 501s 3ms/step - loss: 1293.9750 - mse: 1293.9747 - val_loss: 175.0485 - val_mse: 175.0485\n",
      "Epoch 2/20\n",
      "174982/174982 [==============================] - 514s 3ms/step - loss: 803.0979 - mse: 803.0980 - val_loss: 56.7546 - val_mse: 56.7546\n",
      "Epoch 3/20\n",
      "174982/174982 [==============================] - 498s 3ms/step - loss: 534.2492 - mse: 534.2492 - val_loss: 42.8269 - val_mse: 42.8269\n",
      "Epoch 4/20\n",
      "174982/174982 [==============================] - 498s 3ms/step - loss: 408.6111 - mse: 408.6111 - val_loss: 69.5370 - val_mse: 69.5370\n",
      "Epoch 5/20\n",
      "174982/174982 [==============================] - 485s 3ms/step - loss: 305.2077 - mse: 305.2077 - val_loss: 26.6137 - val_mse: 26.6137\n",
      "Epoch 6/20\n",
      "174982/174982 [==============================] - 468s 3ms/step - loss: 227.3476 - mse: 227.3476 - val_loss: 10.8676 - val_mse: 10.8676\n",
      "Epoch 7/20\n",
      "174982/174982 [==============================] - 365s 2ms/step - loss: 177.1445 - mse: 177.1445 - val_loss: 13.4876 - val_mse: 13.4876\n",
      "Epoch 8/20\n",
      "174982/174982 [==============================] - 279s 2ms/step - loss: 160.3114 - mse: 160.3114 - val_loss: 52.3085 - val_mse: 52.3085\n",
      "Epoch 9/20\n",
      "174982/174982 [==============================] - 278s 2ms/step - loss: 162.0342 - mse: 162.0342 - val_loss: 41.1691 - val_mse: 41.1691\n",
      "Epoch 10/20\n",
      "174982/174982 [==============================] - 278s 2ms/step - loss: 130.9628 - mse: 130.9629 - val_loss: 38.7717 - val_mse: 38.7717\n",
      "Epoch 11/20\n",
      "174982/174982 [==============================] - 278s 2ms/step - loss: 148.2695 - mse: 148.2695 - val_loss: 33.3343 - val_mse: 33.3343\n",
      "Epoch 12/20\n",
      "174982/174982 [==============================] - 279s 2ms/step - loss: 114.2577 - mse: 114.2576 - val_loss: 18.6421 - val_mse: 18.6421\n",
      "Epoch 13/20\n",
      "174982/174982 [==============================] - 393s 2ms/step - loss: 103.6541 - mse: 103.6541 - val_loss: 15.1292 - val_mse: 15.1292\n",
      "Epoch 14/20\n",
      "174982/174982 [==============================] - 480s 3ms/step - loss: 136.8042 - mse: 136.8042 - val_loss: 51.9746 - val_mse: 51.9746\n",
      "Epoch 15/20\n",
      "132096/174982 [=====================>........] - ETA: 1:08:35 - loss: 108.9526 - mse: 108.9526"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-ec9d3c78bf8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m model.fit(X_train, dtrain.target, epochs=epochs, batch_size=BATCH_SIZE\n\u001b[1;32m      7\u001b[0m           \u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m           , verbose=1, callbacks=[EarlyStoppingAtMinLoss])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/aims/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/aims/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aims/lib/python3.5/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aims/lib/python3.5/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aims/lib/python3.5/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aims/lib/python3.5/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aims/lib/python3.5/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/aims/lib/python3.5/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#FITTING THE MODEL\n",
    "BATCH_SIZE = 512 * 3\n",
    "epochs = 20\n",
    "\n",
    "model = get_model()\n",
    "model.fit(X_train, dtrain.target, epochs=epochs, batch_size=BATCH_SIZE\n",
    "          , validation_data=(X_valid, dvalid.target)\n",
    "          , verbose=1, callbacks=[EarlyStoppingAtMinLoss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save entire model to a HDF5 file\n",
    "model.save('group_1_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "## del model  # deletes the existing model\n",
    "\n",
    "# # returns a compiled model\n",
    "# # identical to the previous one\n",
    "# model_saved = load_model('group_1_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RMSE error on dev test: 8.202588843887943\n"
     ]
    }
   ],
   "source": [
    "#EVLUEATE THE MODEL ON DEV TEST: What is it doing?\n",
    "val_preds = model.predict(X_valid)\n",
    "val_preds = target_scaler.inverse_transform(val_preds)\n",
    "val_preds = np.exp(val_preds)-1\n",
    "\n",
    "#mean_absolute_error, mean_squared_log_error\n",
    "y_true = np.array(dvalid.price.values)\n",
    "y_pred = val_preds[:,0]\n",
    "v_rmsle = rmse_cust(y_true, y_pred)\n",
    "print(\" RMSE error on dev test: \"+str(v_rmsle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21.578825],\n",
       "       [55.7756  ],\n",
       "       [27.039185],\n",
       "       [14.071308],\n",
       "       [14.57096 ],\n",
       "       [ 9.747987],\n",
       "       [58.138783],\n",
       "       [33.88641 ],\n",
       "       [12.513379],\n",
       "       [59.96625 ],\n",
       "       [12.089255],\n",
       "       [82.14061 ],\n",
       "       [53.85062 ],\n",
       "       [12.454477],\n",
       "       [47.903843],\n",
       "       [27.716455],\n",
       "       [39.258026],\n",
       "       [29.986303]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_preds = model.predict(X_valid)\n",
    "val_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RMSE error on dev test: 5.243982794241997\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array(dvalid.price.values)\n",
    "y_pred = val_preds[:,0]\n",
    "v_rmsle = rmse_cust(y_true, y_pred)\n",
    "\n",
    "print(\" RMSE error on dev test: \"+str(v_rmsle)) #5.583566891952288 = 29.78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVLUEATE THE MODEL ON DEV TEST: What is it doing?\n",
    "# val_preds = model.predict(X_valid)\n",
    "# val_preds = target_scaler.inverse_transform(val_preds)\n",
    "# val_preds = np.exp(val_preds)+1\n",
    "\n",
    "# #mean_absolute_error, mean_squared_log_error\n",
    "# y_true = np.array(dvalid.price.values)\n",
    "# y_pred = val_preds[:,0]\n",
    "# v_rmsle = rmse_cust(y_true, y_pred)\n",
    "# print(\" RMSE error on dev test: \"+str(v_rmsle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[127.39429 ],\n",
       "       [ 20.67919 ],\n",
       "       [ 46.80042 ],\n",
       "       ...,\n",
       "       [ 43.12809 ],\n",
       "       [ 25.557903],\n",
       "       [ 58.51815 ]], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CREATE PREDICTIONS\n",
    "preds = model.predict(X_test, batch_size=BATCH_SIZE)\n",
    "preds = target_scaler.inverse_transform(preds)\n",
    "preds = np.exp(preds)-1\n",
    "\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aims/anaconda3/envs/aims/lib/python3.5/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>127.394287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.679190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>46.800419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>24.091280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9.894634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       price\n",
       "0   0  127.394287\n",
       "1   1   20.679190\n",
       "2   2   46.800419\n",
       "3   3   24.091280\n",
       "4   4    9.894634"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = test[['id']]\n",
    "output['price']=preds.reshape(-1,1)\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('best_50_epocs.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating on __NAN__ values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 14 columns and we need to investigate each and everyone of them, we have a total of $175000$ examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.dropna(thresh=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna(value='Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.fillna(value='Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='region_2',data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.region_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.region_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='region_2',data=test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns[train.dtypes != 'object']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train.points.isnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.points.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train['points'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['points'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train.price.isnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.price.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['points'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['price_log'] = np.log(train.price+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train['price_log'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train.id.isnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.id.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['id'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__It clear that there is no issue with numerical features, regarding missing values__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns[train.dtypes == 'object']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train.country.isnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"We have {:.4} % of missing values in the feature Country\".format(train.country.isnull().sum()*100/train.index.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='country',data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['country'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = ['Croatia', 'Mexico', 'Georgia', 'Moldova', 'Brazil', 'England', 'Lebanon', 'Morocco', 'Cyprus', 'Macedonia',\n",
    "'Serbia' , 'India', 'Czech Republic', 'Ukraine, Peru', 'Luxembourg', 'Switzerland', 'Lithuania',\n",
    " 'Bosnia and Herzegovina', 'China', 'Slovakia', 'Armenia', 'Japan', 'South Korea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_levels(x, threshold, new_value):\n",
    "    value_counts = x.value_counts()\n",
    "    labels = value_counts.index[value_counts < threshold]\n",
    "    x[np.in1d(x, labels)] = new_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_levels(train.country, 30, 'other')\n",
    "cut_levels(test.country, 30, 'other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='country',data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train.description.isnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.description.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import string  \n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column of word counts to both the training and test set\n",
    "train['desc_len'] = train['description'].apply(lambda x: len(x))\n",
    "test['desc_len'] = test['description'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_tr = train.description\n",
    "description_tst = test.description\n",
    "\n",
    "# texts_tr = clean_doc(train_df.sentence)\n",
    "# texts_tst = clean_doc(test_df.sentence)\n",
    "\n",
    "# Training 92916\n",
    "# Considers only the top \n",
    "# 20,000 words in the dataset\n",
    "max_words = 10\n",
    "\n",
    "tokenizer_tr = Tokenizer(num_words=max_words)\n",
    "# tokenizer_tr = Tokenizer()\n",
    "tokenizer_tr.fit_on_texts(description_tr)\n",
    "# data_tr = tokenizer_tr.texts_to_sequences(description_tr)\n",
    "tfidf_train = tokenizer_tr.texts_to_matrix(description_tr, mode='tfidf')\n",
    "bin_tr = tokenizer_tr.texts_to_matrix(description_tr, mode='binary')\n",
    "\n",
    "\n",
    "# # Testing \n",
    "tokenizer_tst = Tokenizer(num_words=max_words)\n",
    "# # tokenizer_tst = Tokenizer()\n",
    "tokenizer_tst.fit_on_texts(description_tst)\n",
    "# data_tst = tokenizer_tst.texts_to_sequences(texts_tst)\n",
    "tfidf_tst = tokenizer_tr.texts_to_matrix(description_tst, mode='tfidf')\n",
    "bin_tst = tokenizer_tr.texts_to_matrix(description_tst, mode='binary')\n",
    "\n",
    "\n",
    "# word_index = tokenizer_tr.word_index\n",
    "# print('Found %s unique tokens.' % len(set(word_index))) #88582 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train[:]\n",
    "desc_tdidf_tr = pd.DataFrame(tfidf_train)\n",
    "desc_tdidf_tst = pd.DataFrame(tfidf_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_selected = pd.concat([train, desc_tdidf_tr], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_selected = pd.concat([test, desc_tdidf_tst], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Designation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train.designation.isnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(\"We have {:.4} % of missing values in the feature Designation\".format(train.designation.isnull().sum()*100/train.index.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='designation',data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Province"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train.province.isnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"We have {:.4} % of missing values in the feature Province\".format(train.province.isnull().sum()*100/train.index.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.province.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.province.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='province',data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train.region_1.isnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"We have {:.4} % of missing values in the feature Region 1\".format(train.region_1.isnull().sum()*100/train.index.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.region_1.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train.region_2.isnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"We have {:.4} % of missing values in the feature Region 2\".format(train.region_2.isnull().sum()*100/train.index.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.region_2.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taster Name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train.taster_name.isnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"We have {:.4} % of missing values in the feature Taster Name\".format(train.taster_name.isnull().sum()*100/train.index.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.taster_name.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taster Twitter Handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train.taster_twitter_handle.isnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"We have {:.4} % of missing values in the feature Taster Twitter Handle\".format(train.taster_twitter_handle.isnull().sum()*100/train.index.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.taster_twitter_handle.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train.title.isnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"We have {:.4} % of missing values in the feature Title\".format(train.title.isnull().sum()*100/train.index.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.title.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variety "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train.variety.isnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"We have {:.4} % of missing values in the feature Variety\".format(train.variety.isnull().sum()*100/train.index.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.variety.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Winery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train.winery.isnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"We have {:.4} % of missing values in the feature Winery\".format(train.winery.isnull().sum().sum()*100/train.index.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.winery.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_train = train[train.columns[train.dtypes != 'object']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(numerical_train.corr(),cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_train = train[train.columns[train.dtypes == 'object']]\n",
    "categorical_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anove_test_F_value = []\n",
    "# Anove_test_P_value = []\n",
    "# variable_name_list = []\n",
    "\n",
    "# for variable in categorical_train.columns:\n",
    "#     print(variable)\n",
    "#     mod = ols('price ~ '+variable, data = train).fit()\n",
    "#     aov_table = sm.stats.anova_lm(mod, type=2)\n",
    "#     Fvalue = aov_table.loc[variable, 'F']\n",
    "#     Pvalue = aov_table.loc[variable, 'PR(>F)']\n",
    "#     variable_name_list.append(variable)\n",
    "#     Anove_test_F_value.append(Fvalue)\n",
    "#     Anove_test_P_value.append(Pvalue)\n",
    "    \n",
    "# Anova_categorical_variable_test = pd.DataFrame({'Variable':variable_name_list, \"F Value\":Anove_test_F_value, \\\n",
    "#                                                \"P Value\":Anove_test_P_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>> import statsmodels.api as sm\n",
    "# >>> from statsmodels.formula.api import ols\n",
    "# >>> moore = sm.datasets.get_rdataset(\"Moore\", \"carData\", cache=True) # load\n",
    "# >>> data = moore.data\n",
    "# >>> data = data.rename(columns={\"partner.status\" :\n",
    "# ...                             \"partner_status\"}) # make name pythonic\n",
    "\n",
    "# for var in data.columns:\n",
    "#         oore_lm = ols('conformity ~'+var,\n",
    "# ...                 data=data).fit()\n",
    "#         table = sm.stats.anova_lm(moore_lm, typ=2) # Type 2 Anova DataFrame\n",
    "#         print(table)\n",
    "# # >>> moore_lm = ols('conformity ~ C(fcategory, Sum)*C(partner_status, Sum)',\n",
    "# # ...                 data=data).fit()\n",
    "# # >>> table = sm.stats.anova_lm(moore_lm, typ=2) # Type 2 Anova DataFrame\n",
    "# # >>> print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are selecting only those with few missing data to greate one hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_fields = ['region_2', 'taster_name', 'taster_twitter_handle']\n",
    "# train[train.columns[train.dtypes == 'object']], 'country'\n",
    "train_select = numerical_train\n",
    "for each in dummy_fields:\n",
    "    dummies = pd.get_dummies(train[each], prefix=each)\n",
    "    train_select = pd.concat([train_select, dummies], axis=1)\n",
    "\n",
    "numerical_test = test[test.columns[test.dtypes != 'object']]\n",
    "test_select = numerical_test\n",
    "for each in dummy_fields:\n",
    "    dummies = pd.get_dummies(test[each], prefix=each)\n",
    "    test_select = pd.concat([test_select, dummies], axis=1)\n",
    "test_select.drop(['index', 'price'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.country.value_counts().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.country.value_counts().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_select.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quant_features = ['casual', 'registered', 'cnt', 'temp', 'hum', 'windspeed']\n",
    "# Store scalings in a dictionary so we can convert back later\n",
    "scaled_features = {}\n",
    "for each in train_select.columns:\n",
    "    mean, std = train_select[each].mean(), train_select[each].std()\n",
    "    scaled_features[each] = [mean, std]\n",
    "    train_select.loc[:, each] = (train_select[each] - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_select.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# numerical_train_selected_min = MinMaxScaler().fit_transform(numerical_train_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical_train_selected_min.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Scale the columns\n",
    "# numerical_train_selected.points=processed_data.gre/800\n",
    "# processed_data.gpa=processed_data.gpa/4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_select.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = numerical_train_selected.drop(labels=\"price\", axis=1)\n",
    "train_features = train_select.drop(labels=\"price\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = numerical_train_selected['price']\n",
    "train_targets = train_select[['price']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize as opt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_r = RandomForestRegressor(n_estimators=500, criterion=\"mse\", n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_features, train_targets, test_size=0.2, random_state=4)\n",
    "\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aims/anaconda3/envs/aims/lib/python3.5/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-bd6a0175e187>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_r\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/aims/lib/python3.5/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aims/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/anaconda3/envs/aims/lib/python3.5/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'dict'"
     ]
    }
   ],
   "source": [
    "model_r.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = model_r.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (np.sqrt(mean_absolute_error(y_preds,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cat = CatBoostRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Training \n",
    "model_cat.fit(X_train, y_train, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model_cat.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (np.sqrt(metrics.mean_absolute_error(preds,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_test = test[test.columns[test.dtypes != 'object']]\n",
    "categorical_test = test[test.columns[test.dtypes == 'object']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_train_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taster_twitter_handle_cat = pd.get_dummies(categorical_test['taster_twitter_handle'], prefix='taster_twitter_handle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taster_name = pd.get_dummies(categorical_train['taster_name'], prefix='taster_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_2  = pd.get_dummies(categorical_train['region_2'], prefix='region_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country  = pd.get_dummies(categorical_train['country'], prefix='country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_test.drop('price', implace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_test_selected = pd.concat([numerical_test, taster_twitter_handle_cat, taster_name,\n",
    "                                      region_2, country], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udacity Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# In the my_answers.py\n",
    "#############\n",
    "\n",
    "from my_answers import NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(y, Y):\n",
    "    return np.sqrt(np.mean((y-Y)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y, Y):\n",
    "    return np.mean((y-Y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, val_features, train_targets, val_targets = train_test_split(train_features, \n",
    "                                                    train_targets, test_size=0.2, random_state=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "####################\n",
    "### Set the hyperparameters in you myanswers.py file ###\n",
    "####################\n",
    "\n",
    "from my_answers import iterations, learning_rate, hidden_nodes, output_nodes\n",
    "\n",
    "\n",
    "N_i = train_features.shape[1]\n",
    "network = NeuralNetwork(N_i, hidden_nodes, output_nodes, learning_rate)\n",
    "\n",
    "losses = {'train':[], 'validation':[]}\n",
    "for ii in range(iterations):\n",
    "    # Go through a random batch of 128 records from the training data set\n",
    "    batch = np.random.choice(train_features.index, size=128)\n",
    "    X, y = train_features.ix[batch].values, train_targets.ix[batch]['price']\n",
    "                             \n",
    "    network.train(X, y)\n",
    "    \n",
    "    # Printing out the training progress\n",
    "    train_loss = MSE(network.run(train_features).T, train_targets['price'].values)\n",
    "    val_loss = MSE(network.run(val_features).T, val_targets['price'].values)\n",
    "    sys.stdout.write(\"\\rProgress: {:2.1f}\".format(100 * ii/float(iterations)) \\\n",
    "                     + \"% ... Training loss: \" + str(train_loss)[:5] \\\n",
    "                     + \" ... Validation loss: \" + str(val_loss)[:5])\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    losses['train'].append(train_loss)\n",
    "    losses['validation'].append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = network.run(val_features).T*scaled_features['price'][1]  + scaled_features['price'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE((val_targets['price']*scaled_features['price'][1] + scaled_features['price'][0]).values, predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTher approach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.price.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['price_log']=np.log(train.price+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11,7))\n",
    "\n",
    "sns.countplot(x='price_log', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train['price_log'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
